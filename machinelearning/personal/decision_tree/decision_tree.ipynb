{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree op Iris\n",
    "\n",
    "Een decision tree model is een machine learning-algoritme dat gebruikt wordt voor zowel classificatie- als regressietaken. Het model werkt door data in een boomstructuur te splitsen, waarbij elke interne knoop een \"beslissing\" voorstelt gebaseerd op een bepaalde eigenschap van de data, en elke bladknoop een uitkomst of klasse. Hier is een korte uitleg over de belangrijkste kenmerken en stappen van een decision tree:\n",
    "\n",
    "### Kenmerken van een Decision Tree Model\n",
    "\n",
    "1. Boomstructuur: De decision tree bestaat uit knopen (nodes) die data splitsen op basis van bepaalde kenmerken of attributen.\n",
    "2. Interne Knoop: Een interne knoop vertegenwoordigt een beslissingsregel op een attribuut.\n",
    "3. Bladknoop: Een bladknoop vertegenwoordigt een uiteindelijke beslissing of classificatie.\n",
    "4. Splitscriteria: Criteria zoals Gini-impurity of information gain (voor classificatie) en mean squared error (voor regressie) worden gebruikt om de splitsingen te bepalen.\n",
    "5. Diepte van de Boom: Dit bepaalt hoeveel niveaus de boom heeft. Een diepere boom kan beter fitten op training data maar heeft een hoger risico op overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voorbeeld dataset: Iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Splitsen van de dataset in training en test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiseren van de Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Trainen van het model\n",
    "clf = clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "# Voorspellen met de test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evalueren van de prestaties van het model\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusie Matrix:\n",
      " [[14  0  0]\n",
      " [ 0 17  1]\n",
      " [ 0  1 12]]\n",
      "Classificatie Rapport:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.94      0.94      0.94        18\n",
      "           2       0.92      0.92      0.92        13\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.96      0.96      0.96        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Genereren van de confusie matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusie Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Genereren van een gedetailleerd classificatierapport\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classificatie Rapport:\\n\", class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusie en Analyse van het Decision Tree Model\n",
    "\n",
    "Het decision tree model presteert uitstekend met een overall accuracy van 95.56%. De details uit de confusie matrix en het classificatierapport bieden een nog dieper inzicht in de prestaties van het model:\n",
    "Confusie Matrix\n",
    "\n",
    "- Klasse 0: Alle 14 voorbeelden zijn correct geclassificeerd (100% accuraat).\n",
    "- Klasse 1: Van de 18 voorbeelden is er slechts 1 fout geclassificeerd (94% accuraat).\n",
    "- Klasse 2: Van de 13 voorbeelden is er eveneens slechts 1 fout geclassificeerd (92% accuraat).\n",
    "\n",
    "### Classificatie Rapport\n",
    "\n",
    "- **Precision:** De precisie voor klassen 0, 1, en 2 is respectievelijk 1.00, 0.94, en 0.92. Dit betekent dat wanneer het model een voorbeeld als een bepaalde klasse voorspelt, het in 100% (klasse 0), 94% (klasse 1), en 92% (klasse 2) van de gevallen correct is.\n",
    "- **Recall:** De recall voor klassen 0, 1, en 2 is eveneens hoog, wat aangeeft dat het model effectief voorbeelden binnen deze klassen herkent.\n",
    "- **F1-score:** De f1-scores zijn hoog voor alle klassen (1.00 voor klasse 0, 0.94 voor klasse 1, en 0.92 voor klasse 2), wat een goede balans tussen precisie en recall aangeeft.\n",
    "- **Macro en Weighted Averages:** De macro gemiddelde scores van 0.96 voor precisie, recall, en f1-score suggereren dat het model goed presteert over alle klassen. De gewogen gemiddelde scores, die rekening houden met de verdeling van de klassen, zijn ook 0.96.\n",
    "\n",
    "### Samenvatting\n",
    "\n",
    "Het decision tree model vertoont zeer goede prestaties met een hoge nauwkeurigheid en evenwichtige prestaties over alle klassen. Hier zijn enkele belangrijke punten:\n",
    "\n",
    "1. **Uitstekende Nauwkeurigheid:** Met een accuracy van 95.56% presteert het model bijna perfect.\n",
    "2. **Hoge Precision en Recall:** De hoge precisie en recall over alle klassen laten zien dat het model zowel accuraat als volledig is in zijn voorspellingen.\n",
    "3. **Balans Tussen Klassen:** Er is een goede balans in de prestaties van het model over de verschillende klassen, zonder significante bias naar een specifieke klasse.\n",
    "4. **Lichte Verbeterpunten:** Hoewel de prestaties al uitstekend zijn, kan er wellicht nog een kleine verbetering worden behaald voor klasse 1 en 2, waar er enkele fouten zijn.\n",
    "\n",
    "Over het algemeen is het decision tree model zeer betrouwbaar en goed geschikt voor de taak waarvoor het is getraind. Verdere verbeteringen zouden kunnen worden onderzocht door fine-tuning van hyperparameters, het toepassen van meer geavanceerde technieken zoals ensemble methoden (bijv. Random Forest), of het verzamelen van meer data om de robuustheid van het model te vergroten."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
