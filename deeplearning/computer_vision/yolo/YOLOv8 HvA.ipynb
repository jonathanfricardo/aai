{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6MPjfT5NrKQ"
   },
   "source": [
    "# YOLO v8 for HvA\n",
    "\n",
    "- Minor Applied AI, Computer Vision les 4 \n",
    "- Michiel Bontenbal & Maarten Post\n",
    "- woensdag 3 april 2024\n",
    "\n",
    "\n",
    "Source: https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb#scrollTo=zR9ZbuQCH7FX\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mGmQbAO5pQb"
   },
   "source": [
    "# Setup\n",
    "\n",
    "\n",
    "YOLO is nu van een bedrijf Ultralytics en we gaan hun repo gebruiken. Zie https://www.ultralytics.com/nl\n",
    "\n",
    "Pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "executionInfo": {
     "elapsed": 216,
     "status": "error",
     "timestamp": 1712056873234,
     "user": {
      "displayName": "Michiel Bontenbal",
      "userId": "03976569418489878594"
     },
     "user_tz": -120
    },
    "id": "wbvMlHd_QwMG",
    "outputId": "2792633d-7f18-4365-d60d-9e299012f017"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.42 üöÄ Python-3.11.5 torch-2.2.2 CPU (Apple M2)\n",
      "Setup complete ‚úÖ (8 CPUs, 16.0 GB RAM, 113.1/228.3 GB disk)\n"
     ]
    }
   ],
   "source": [
    "%pip install ultralytics\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JnkELT0cIJg"
   },
   "source": [
    "# 1. Predict with CLI\n",
    "\n",
    "YOLOv8 may be used directly in the Command Line Interface (CLI) with a `yolo` command \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zR9ZbuQCH7FX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.23M/6.23M [00:00<00:00, 26.7MB/s]\n",
      "Ultralytics YOLOv8.1.42 üöÄ Python-3.11.5 torch-2.2.2 CPU (Apple M2)\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "Downloading https://ultralytics.com/images/zidane.jpg to 'zidane.jpg'...\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 165k/165k [00:00<00:00, 8.68MB/s]\n",
      "image 1/1 /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/zidane.jpg: 384x640 2 persons, 1 tie, 71.8ms\n",
      "Speed: 2.6ms preprocess, 71.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "üí° Learn more at https://docs.ultralytics.com/modes/predict\n",
      "Ultralytics YOLOv8.1.42 üöÄ Python-3.11.5 torch-2.2.2 CPU (Apple M2)\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "Found https://ultralytics.com/images/zidane.jpg locally at zidane.jpg\n",
      "image 1/1 /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/zidane.jpg: 384x640 2 persons, 1 tie, 77.5ms\n",
      "Speed: 2.1ms preprocess, 77.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict2\u001b[0m\n",
      "üí° Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "# Run inference on an image with YOLOv8n\n",
    "!yolo predict model=yolov8n.pt source='https://ultralytics.com/images/zidane.jpg'\n",
    "!yolo predict model=yolov8n.pt source='https://ultralytics.com/images/zidane.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkAzDWJ7cWTr"
   },
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/212889447-69e5bdf1-5800-4e29-835e-2ed2336dede2.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUMOQ0OeDBJG"
   },
   "source": [
    "# 2. Python Usage\n",
    "\n",
    "YOLOv8 was reimagined using Python-first principles for the most seamless Python YOLO experience yet. YOLOv8 models can be loaded from a trained checkpoint or created from scratch. Then methods are used to train, val, predict, and export the model. See detailed Python usage examples in the [YOLOv8 Python Docs](https://docs.ultralytics.com/usage/python/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bpF9-vS_DAaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.42 üöÄ Python-3.11.5 torch-2.2.2 CPU (Apple M2)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=coco128.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "\n",
      "Dataset 'coco128.yaml' images not found ‚ö†Ô∏è, missing path '/Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/coco128/images/train2017'\n",
      "Downloading https://ultralytics.com/assets/coco128.zip to '/Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/coco128.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.66M/6.66M [00:00<00:00, 24.2MB/s]\n",
      "Unzipping /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/coco128.zip to /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/coco128...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 263/263 [00:00<00:00, 3487.83file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset download success ‚úÖ (1.7s), saved to \u001b[1m/Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/coco128/labels/train2017... 126 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<00:00, 2413.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/coco128/labels/train2017.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3         0G      1.154      1.491      1.217        215        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [01:47<00:00, 13.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:35<00:00,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.661      0.534      0.619      0.459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3         0G      1.224      1.404      1.265        245        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [01:47<00:00, 13.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:35<00:00,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.671      0.552      0.628       0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3         0G      1.141      1.352      1.221        280        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [01:43<00:00, 12.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:34<00:00,  8.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.686      0.558      0.635      0.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.119 hours.\n",
      "Optimizer stripped from runs/detect/train/weights/last.pt, 6.5MB\n",
      "Optimizer stripped from runs/detect/train/weights/best.pt, 6.5MB\n",
      "\n",
      "Validating runs/detect/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.1.42 üöÄ Python-3.11.5 torch-2.2.2 CPU (Apple M2)\n",
      "Model summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:30<00:00,  7.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.685      0.558      0.635      0.474\n",
      "                person        128        254      0.822      0.654      0.774      0.542\n",
      "               bicycle        128          6      0.492      0.333      0.327      0.282\n",
      "                   car        128         46      0.901      0.217      0.284      0.186\n",
      "            motorcycle        128          5      0.674       0.83      0.938      0.744\n",
      "              airplane        128          6      0.813      0.833      0.927      0.717\n",
      "                   bus        128          7       0.74      0.714      0.729      0.657\n",
      "                 train        128          3      0.563      0.667      0.775      0.687\n",
      "                 truck        128         12          1       0.37      0.512      0.345\n",
      "                  boat        128          6      0.414      0.247      0.413      0.285\n",
      "         traffic light        128         14      0.748      0.212      0.201      0.138\n",
      "             stop sign        128          2       0.92          1      0.995      0.729\n",
      "                 bench        128          9      0.828      0.538      0.639      0.401\n",
      "                  bird        128         16      0.923      0.748      0.908      0.556\n",
      "                   cat        128          4      0.877          1      0.995      0.843\n",
      "                   dog        128          9      0.721      0.889      0.874      0.632\n",
      "                 horse        128          2       0.56          1      0.995      0.497\n",
      "              elephant        128         17      0.958      0.824      0.907      0.689\n",
      "                  bear        128          1       0.63          1      0.995      0.995\n",
      "                 zebra        128          4      0.861          1      0.995      0.965\n",
      "               giraffe        128          9        0.9      0.999      0.973      0.735\n",
      "              backpack        128          6      0.628      0.333      0.376       0.23\n",
      "              umbrella        128         18      0.782        0.5      0.656      0.452\n",
      "               handbag        128         19      0.412     0.0434      0.185     0.0982\n",
      "                   tie        128          7      0.704      0.685      0.644      0.476\n",
      "              suitcase        128          4      0.661          1      0.828      0.592\n",
      "               frisbee        128          5      0.626        0.8      0.733       0.64\n",
      "                  skis        128          1      0.697          1      0.995      0.497\n",
      "             snowboard        128          7      0.688      0.714      0.756      0.501\n",
      "           sports ball        128          6      0.692      0.385      0.502      0.274\n",
      "                  kite        128         10       0.82       0.46      0.577      0.213\n",
      "          baseball bat        128          4      0.413       0.25      0.372      0.186\n",
      "        baseball glove        128          7      0.667      0.429      0.429      0.295\n",
      "            skateboard        128          5      0.786        0.6        0.6      0.426\n",
      "         tennis racket        128          7      0.515      0.286      0.466      0.319\n",
      "                bottle        128         18      0.537      0.389       0.37      0.215\n",
      "            wine glass        128         16      0.582      0.524      0.584      0.357\n",
      "                   cup        128         36      0.604       0.25      0.399      0.283\n",
      "                  fork        128          6          1      0.302      0.363      0.229\n",
      "                 knife        128         16      0.639        0.5      0.614      0.369\n",
      "                 spoon        128         22      0.619      0.227      0.363      0.189\n",
      "                  bowl        128         28      0.668      0.679      0.647      0.539\n",
      "                banana        128          1          0          0      0.124     0.0364\n",
      "              sandwich        128          2      0.341      0.524      0.497      0.497\n",
      "                orange        128          4          1      0.392      0.995      0.666\n",
      "              broccoli        128         11      0.456      0.182      0.256      0.213\n",
      "                carrot        128         24      0.733        0.5      0.666      0.432\n",
      "               hot dog        128          2      0.615          1      0.828      0.796\n",
      "                 pizza        128          5      0.806          1      0.995       0.85\n",
      "                 donut        128         14      0.657          1       0.94      0.852\n",
      "                  cake        128          4      0.727          1      0.995       0.88\n",
      "                 chair        128         35       0.52      0.486      0.443      0.259\n",
      "                 couch        128          6       0.75        0.5      0.736       0.52\n",
      "          potted plant        128         14      0.799      0.643      0.733      0.487\n",
      "                   bed        128          3      0.764      0.667       0.83      0.619\n",
      "          dining table        128         13      0.507      0.615      0.517      0.419\n",
      "                toilet        128          2      0.636        0.5      0.828      0.796\n",
      "                    tv        128          2      0.583      0.749      0.828      0.762\n",
      "                laptop        128          3          1       0.47      0.755      0.595\n",
      "                 mouse        128          2          1          0     0.0394    0.00394\n",
      "                remote        128          8      0.849        0.5       0.57      0.493\n",
      "            cell phone        128          8          0          0      0.058     0.0376\n",
      "             microwave        128          3      0.591      0.667       0.83      0.733\n",
      "                  oven        128          5      0.465        0.4      0.343      0.273\n",
      "                  sink        128          6      0.358      0.167      0.233      0.141\n",
      "          refrigerator        128          5      0.614        0.4      0.682      0.556\n",
      "                  book        128         29      0.625      0.116      0.374      0.194\n",
      "                 clock        128          9      0.779      0.786      0.892      0.738\n",
      "                  vase        128          2      0.377          1      0.828      0.795\n",
      "              scissors        128          1          1          0      0.199     0.0597\n",
      "            teddy bear        128         21          1      0.369      0.643      0.433\n",
      "            toothbrush        128          5          1      0.523      0.778       0.51\n",
      "Speed: 1.5ms preprocess, 231.0ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
      "Ultralytics YOLOv8.1.42 üöÄ Python-3.11.5 torch-2.2.2 CPU (Apple M2)\n",
      "Model summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:34<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.665      0.565      0.631      0.472\n",
      "                person        128        254      0.816      0.665      0.774      0.543\n",
      "               bicycle        128          6       0.48      0.333      0.327      0.282\n",
      "                   car        128         46      0.844      0.217      0.284      0.186\n",
      "            motorcycle        128          5      0.679       0.85      0.898       0.72\n",
      "              airplane        128          6      0.798      0.833      0.927      0.717\n",
      "                   bus        128          7      0.659      0.714      0.729      0.657\n",
      "                 train        128          3      0.556      0.667      0.775      0.687\n",
      "                 truck        128         12      0.947      0.417      0.492      0.301\n",
      "                  boat        128          6      0.303      0.226      0.356      0.187\n",
      "         traffic light        128         14      0.742      0.207      0.205       0.14\n",
      "             stop sign        128          2      0.888          1      0.995      0.729\n",
      "                 bench        128          9      0.837      0.572      0.639      0.401\n",
      "                  bird        128         16      0.913       0.75      0.894      0.545\n",
      "                   cat        128          4      0.869          1      0.995      0.843\n",
      "                   dog        128          9      0.665      0.889      0.874      0.632\n",
      "                 horse        128          2      0.546          1      0.995      0.497\n",
      "              elephant        128         17      0.951      0.824      0.907      0.689\n",
      "                  bear        128          1      0.619          1      0.995      0.995\n",
      "                 zebra        128          4      0.856          1      0.995      0.965\n",
      "               giraffe        128          9      0.809          1      0.951      0.759\n",
      "              backpack        128          6      0.617      0.333      0.391      0.235\n",
      "              umbrella        128         18      0.741        0.5      0.654      0.451\n",
      "               handbag        128         19      0.565     0.0731      0.185     0.0974\n",
      "                   tie        128          7      0.712      0.706      0.644      0.476\n",
      "              suitcase        128          4      0.618          1      0.828      0.592\n",
      "               frisbee        128          5       0.61        0.8      0.732       0.64\n",
      "                  skis        128          1      0.645          1      0.995      0.497\n",
      "             snowboard        128          7      0.677      0.714      0.755      0.501\n",
      "           sports ball        128          6        0.7        0.4      0.502      0.274\n",
      "                  kite        128         10      0.833      0.498      0.578      0.213\n",
      "          baseball bat        128          4       0.47       0.25      0.348      0.198\n",
      "        baseball glove        128          7      0.638      0.429      0.429      0.316\n",
      "            skateboard        128          5      0.849        0.6        0.6      0.426\n",
      "         tennis racket        128          7      0.735      0.403      0.501      0.336\n",
      "                bottle        128         18      0.478      0.389       0.37      0.227\n",
      "            wine glass        128         16      0.568      0.562      0.563      0.346\n",
      "                   cup        128         36      0.582      0.271      0.413      0.291\n",
      "                  fork        128          6      0.568      0.167      0.247      0.187\n",
      "                 knife        128         16      0.471      0.502      0.585       0.36\n",
      "                 spoon        128         22        0.7      0.227      0.357      0.183\n",
      "                  bowl        128         28      0.685      0.698      0.669      0.521\n",
      "                banana        128          1          0          0     0.0995     0.0318\n",
      "              sandwich        128          2      0.216      0.325      0.497      0.497\n",
      "                orange        128          4          1      0.419      0.995      0.666\n",
      "              broccoli        128         11      0.472      0.182      0.259      0.208\n",
      "                carrot        128         24      0.667      0.583      0.675      0.432\n",
      "               hot dog        128          2      0.624          1      0.828      0.796\n",
      "                 pizza        128          5      0.864          1      0.995      0.853\n",
      "                 donut        128         14      0.655          1      0.933      0.846\n",
      "                  cake        128          4      0.614          1      0.995       0.88\n",
      "                 chair        128         35      0.485      0.514       0.44      0.252\n",
      "                 couch        128          6      0.795       0.65      0.774      0.599\n",
      "          potted plant        128         14      0.732      0.643      0.733      0.487\n",
      "                   bed        128          3      0.746      0.667      0.913       0.71\n",
      "          dining table        128         13      0.502      0.615      0.508        0.4\n",
      "                toilet        128          2      0.624        0.5      0.828      0.796\n",
      "                    tv        128          2      0.604      0.812      0.828      0.762\n",
      "                laptop        128          3          1      0.493      0.712       0.57\n",
      "                 mouse        128          2          1          0     0.0517    0.00517\n",
      "                remote        128          8      0.836        0.5      0.605      0.513\n",
      "            cell phone        128          8          0          0     0.0572     0.0372\n",
      "             microwave        128          3      0.573      0.667       0.83      0.717\n",
      "                  oven        128          5      0.444        0.4      0.343      0.273\n",
      "                  sink        128          6      0.371      0.167      0.193      0.121\n",
      "          refrigerator        128          5      0.618        0.4      0.682      0.536\n",
      "                  book        128         29      0.662      0.136      0.383      0.205\n",
      "                 clock        128          9      0.782      0.798      0.893      0.738\n",
      "                  vase        128          2      0.365          1      0.828      0.795\n",
      "              scissors        128          1          1          0      0.199     0.0597\n",
      "            teddy bear        128         21          1      0.374       0.64      0.431\n",
      "            toothbrush        128          5      0.718        0.6      0.743      0.461\n",
      "Speed: 0.9ms preprocess, 262.2ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n",
      "\n",
      "Downloading https://ultralytics.com/images/bus.jpg to 'bus.jpg'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 476k/476k [00:00<00:00, 11.2MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 84.6ms\n",
      "Speed: 3.1ms preprocess, 84.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.42 üöÄ Python-3.11.5 torch-2.2.2 CPU (Apple M2)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/detect/train/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnx>=1.12.0'] not found, attempting AutoUpdate...\n",
      "Collecting onnx>=1.12.0\n",
      "  Downloading onnx-1.16.0-cp311-cp311-macosx_10_15_universal2.whl.metadata (16 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/jonathanricardo/anaconda3/lib/python3.11/site-packages (from onnx>=1.12.0) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /Users/jonathanricardo/anaconda3/lib/python3.11/site-packages (from onnx>=1.12.0) (4.23.4)\n",
      "Downloading onnx-1.16.0-cp311-cp311-macosx_10_15_universal2.whl (16.5 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: onnx\n",
      "Successfully installed onnx-1.16.0\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 7.0s, installed 1 package: ['onnx>=1.12.0']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 8.5s, saved as 'runs/detect/train/weights/best.onnx' (12.2 MB)\n",
      "\n",
      "Export complete (8.9s)\n",
      "Results saved to \u001b[1m/Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/runs/detect/train/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=runs/detect/train/weights/best.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=runs/detect/train/weights/best.onnx imgsz=640 data=/Users/jonathanricardo/anaconda3/lib/python3.11/site-packages/ultralytics/cfg/datasets/coco128.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('yolov8n.yaml')  # build a new model from scratch\n",
    "model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Use the model\n",
    "results = model.train(data='coco128.yaml', epochs=3)  # train the model\n",
    "results = model.val()  # evaluate model performance on the validation set\n",
    "results = model('https://ultralytics.com/images/bus.jpg')  # predict on an image\n",
    "results = model.export(format='onnx')  # export the model to ONNX format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Phm9ccmOKye5"
   },
   "source": [
    "# 3. Tasks\n",
    "\n",
    "YOLOv8 can train, val, predict and export models for the most common tasks in vision AI: [Detect](https://docs.ultralytics.com/tasks/detect/), [Segment](https://docs.ultralytics.com/tasks/segment/), [Classify](https://docs.ultralytics.com/tasks/classify/) and [Pose](https://docs.ultralytics.com/tasks/pose/). See [YOLOv8 Tasks Docs](https://docs.ultralytics.com/tasks/) for more information.\n",
    "\n",
    "<br><img width=\"1024\" src=\"https://raw.githubusercontent.com/ultralytics/assets/main/im/banner-tasks.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yq26lwpYK1lq"
   },
   "source": [
    "## 1. Detection\n",
    "\n",
    "YOLOv8 _detection_ models have no suffix and are the default YOLOv8 models, i.e. `yolov8n.pt` and are pretrained on COCO. See [Detection Docs](https://docs.ultralytics.com/tasks/detect/) for full details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8Go5qqS9LbC5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.42 üöÄ Python-3.11.5 torch-2.2.2 CPU (Apple M2)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=coco128.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train3', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train3/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train3\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3         0G      1.154      1.491      1.217        215        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:05<00:00, 15.63s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:38<00:00,  9.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.661      0.534      0.619      0.459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3         0G      1.224      1.404      1.265        245        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [01:45<00:00, 13.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:36<00:00,  9.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.671      0.552      0.628       0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3         0G      1.141      1.352      1.221        280        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [01:52<00:00, 14.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:35<00:00,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.686      0.558      0.635      0.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.130 hours.\n",
      "Optimizer stripped from runs/detect/train3/weights/last.pt, 6.5MB\n",
      "Optimizer stripped from runs/detect/train3/weights/best.pt, 6.5MB\n",
      "\n",
      "Validating runs/detect/train3/weights/best.pt...\n",
      "Ultralytics YOLOv8.1.42 üöÄ Python-3.11.5 torch-2.2.2 CPU (Apple M2)\n",
      "Model summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:34<00:00,  8.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.685      0.558      0.635      0.474\n",
      "                person        128        254      0.822      0.654      0.774      0.542\n",
      "               bicycle        128          6      0.492      0.333      0.327      0.282\n",
      "                   car        128         46      0.901      0.217      0.284      0.186\n",
      "            motorcycle        128          5      0.674       0.83      0.938      0.744\n",
      "              airplane        128          6      0.813      0.833      0.927      0.717\n",
      "                   bus        128          7       0.74      0.714      0.729      0.657\n",
      "                 train        128          3      0.563      0.667      0.775      0.687\n",
      "                 truck        128         12          1       0.37      0.512      0.345\n",
      "                  boat        128          6      0.414      0.247      0.413      0.285\n",
      "         traffic light        128         14      0.748      0.212      0.201      0.138\n",
      "             stop sign        128          2       0.92          1      0.995      0.729\n",
      "                 bench        128          9      0.828      0.538      0.639      0.401\n",
      "                  bird        128         16      0.923      0.748      0.908      0.556\n",
      "                   cat        128          4      0.877          1      0.995      0.843\n",
      "                   dog        128          9      0.721      0.889      0.874      0.632\n",
      "                 horse        128          2       0.56          1      0.995      0.497\n",
      "              elephant        128         17      0.958      0.824      0.907      0.689\n",
      "                  bear        128          1       0.63          1      0.995      0.995\n",
      "                 zebra        128          4      0.861          1      0.995      0.965\n",
      "               giraffe        128          9        0.9      0.999      0.973      0.735\n",
      "              backpack        128          6      0.628      0.333      0.376       0.23\n",
      "              umbrella        128         18      0.782        0.5      0.656      0.452\n",
      "               handbag        128         19      0.412     0.0434      0.185     0.0982\n",
      "                   tie        128          7      0.704      0.685      0.644      0.476\n",
      "              suitcase        128          4      0.661          1      0.828      0.592\n",
      "               frisbee        128          5      0.626        0.8      0.733       0.64\n",
      "                  skis        128          1      0.697          1      0.995      0.497\n",
      "             snowboard        128          7      0.688      0.714      0.756      0.501\n",
      "           sports ball        128          6      0.692      0.385      0.502      0.274\n",
      "                  kite        128         10       0.82       0.46      0.577      0.213\n",
      "          baseball bat        128          4      0.413       0.25      0.372      0.186\n",
      "        baseball glove        128          7      0.667      0.429      0.429      0.295\n",
      "            skateboard        128          5      0.786        0.6        0.6      0.426\n",
      "         tennis racket        128          7      0.515      0.286      0.466      0.319\n",
      "                bottle        128         18      0.537      0.389       0.37      0.215\n",
      "            wine glass        128         16      0.582      0.524      0.584      0.357\n",
      "                   cup        128         36      0.604       0.25      0.399      0.283\n",
      "                  fork        128          6          1      0.302      0.363      0.229\n",
      "                 knife        128         16      0.639        0.5      0.614      0.369\n",
      "                 spoon        128         22      0.619      0.227      0.363      0.189\n",
      "                  bowl        128         28      0.668      0.679      0.647      0.539\n",
      "                banana        128          1          0          0      0.124     0.0364\n",
      "              sandwich        128          2      0.341      0.524      0.497      0.497\n",
      "                orange        128          4          1      0.392      0.995      0.666\n",
      "              broccoli        128         11      0.456      0.182      0.256      0.213\n",
      "                carrot        128         24      0.733        0.5      0.666      0.432\n",
      "               hot dog        128          2      0.615          1      0.828      0.796\n",
      "                 pizza        128          5      0.806          1      0.995       0.85\n",
      "                 donut        128         14      0.657          1       0.94      0.852\n",
      "                  cake        128          4      0.727          1      0.995       0.88\n",
      "                 chair        128         35       0.52      0.486      0.443      0.259\n",
      "                 couch        128          6       0.75        0.5      0.736       0.52\n",
      "          potted plant        128         14      0.799      0.643      0.733      0.487\n",
      "                   bed        128          3      0.764      0.667       0.83      0.619\n",
      "          dining table        128         13      0.507      0.615      0.517      0.419\n",
      "                toilet        128          2      0.636        0.5      0.828      0.796\n",
      "                    tv        128          2      0.583      0.749      0.828      0.762\n",
      "                laptop        128          3          1       0.47      0.755      0.595\n",
      "                 mouse        128          2          1          0     0.0394    0.00394\n",
      "                remote        128          8      0.849        0.5       0.57      0.493\n",
      "            cell phone        128          8          0          0      0.058     0.0376\n",
      "             microwave        128          3      0.591      0.667       0.83      0.733\n",
      "                  oven        128          5      0.465        0.4      0.343      0.273\n",
      "                  sink        128          6      0.358      0.167      0.233      0.141\n",
      "          refrigerator        128          5      0.614        0.4      0.682      0.556\n",
      "                  book        128         29      0.625      0.116      0.374      0.194\n",
      "                 clock        128          9      0.779      0.786      0.892      0.738\n",
      "                  vase        128          2      0.377          1      0.828      0.795\n",
      "              scissors        128          1          1          0      0.199     0.0597\n",
      "            teddy bear        128         21          1      0.369      0.643      0.433\n",
      "            toothbrush        128          5          1      0.523      0.778       0.51\n",
      "Speed: 1.6ms preprocess, 259.6ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train3\u001b[0m\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 96.9ms\n",
      "Speed: 2.8ms preprocess, 96.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       " obb: None\n",
       " orig_img: array([[[122, 148, 172],\n",
       "         [120, 146, 170],\n",
       "         [125, 153, 177],\n",
       "         ...,\n",
       "         [157, 170, 184],\n",
       "         [158, 171, 185],\n",
       "         [158, 171, 185]],\n",
       " \n",
       "        [[127, 153, 177],\n",
       "         [124, 150, 174],\n",
       "         [127, 155, 179],\n",
       "         ...,\n",
       "         [158, 171, 185],\n",
       "         [159, 172, 186],\n",
       "         [159, 172, 186]],\n",
       " \n",
       "        [[128, 154, 178],\n",
       "         [126, 152, 176],\n",
       "         [126, 154, 178],\n",
       "         ...,\n",
       "         [158, 171, 185],\n",
       "         [158, 171, 185],\n",
       "         [158, 171, 185]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[185, 185, 191],\n",
       "         [182, 182, 188],\n",
       "         [179, 179, 185],\n",
       "         ...,\n",
       "         [114, 107, 112],\n",
       "         [115, 105, 111],\n",
       "         [116, 106, 112]],\n",
       " \n",
       "        [[157, 157, 163],\n",
       "         [180, 180, 186],\n",
       "         [185, 186, 190],\n",
       "         ...,\n",
       "         [107,  97, 103],\n",
       "         [102,  92,  98],\n",
       "         [108,  98, 104]],\n",
       " \n",
       "        [[112, 112, 118],\n",
       "         [160, 160, 166],\n",
       "         [169, 170, 174],\n",
       "         ...,\n",
       "         [ 99,  89,  95],\n",
       "         [ 96,  86,  92],\n",
       "         [102,  92,  98]]], dtype=uint8)\n",
       " orig_shape: (1080, 810)\n",
       " path: '/Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/bus.jpg'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/train32'\n",
       " speed: {'preprocess': 2.7971267700195312, 'inference': 96.91715240478516, 'postprocess': 0.8637905120849609}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load YOLOv8n, train it on COCO128 for 3 epochs and predict an image with it\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n.pt')  # load a pretrained YOLOv8n detection model\n",
    "model.train(data='coco128.yaml', epochs=3)  # train the model\n",
    "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ZW58jUzK66B"
   },
   "source": [
    "## 2. Segmentation\n",
    "\n",
    "YOLOv8 _segmentation_ models use the `-seg` suffix, i.e. `yolov8n-seg.pt` and are pretrained on COCO. See [Segmentation Docs](https://docs.ultralytics.com/tasks/segment/) for full details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WFPJIQl_L5HT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n-seg.pt to 'yolov8n-seg.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.73M/6.73M [00:00<00:00, 9.40MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.42 üöÄ Python-3.11.5 torch-2.2.2 CPU (Apple M2)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolov8n-seg.pt, data=coco128-seg.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
      "\n",
      "Dataset 'coco128-seg.yaml' images not found ‚ö†Ô∏è, missing path '/Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/coco128-seg/images/train2017'\n",
      "Downloading https://ultralytics.com/assets/coco128-seg.zip to '/Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/coco128-seg.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.79M/6.79M [00:00<00:00, 11.3MB/s]\n",
      "Unzipping /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/coco128-seg.zip to /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/coco128-seg...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 263/263 [00:00<00:00, 3557.81file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset download success ‚úÖ (2.0s), saved to \u001b[1m/Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets\u001b[0m\n",
      "\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   1150432  ultralytics.nn.modules.head.Segment          [80, 32, 64, [64, 128, 256]]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n-seg summary: 261 layers, 3409968 parameters, 3409952 gradients, 12.8 GFLOPs\n",
      "\n",
      "Transferred 417/417 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/coco128-seg/labels/train2017... 126 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<00:00, 2037.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/coco128-seg/labels/train2017.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/coco128-seg/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/segment/train/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3         0G      1.096      2.605      1.527      1.149        221        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:33<00:00, 19.21s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:47<00:00, 11.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.581      0.571      0.591      0.442      0.561      0.539      0.553      0.364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3         0G       1.15      2.652      1.389      1.176        250        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:30<00:00, 18.86s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:52<00:00, 13.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.599      0.573      0.605      0.451      0.569      0.533      0.559      0.371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3         0G      1.055      2.549      1.359      1.148        143        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:27<00:00, 18.45s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:47<00:00, 11.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.585      0.595      0.608      0.453      0.565      0.544      0.566      0.373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.169 hours.\n",
      "Optimizer stripped from runs/segment/train/weights/last.pt, 7.1MB\n",
      "Optimizer stripped from runs/segment/train/weights/best.pt, 7.1MB\n",
      "\n",
      "Validating runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.1.42 üöÄ Python-3.11.5 torch-2.2.2 CPU (Apple M2)\n",
      "YOLOv8n-seg summary (fused): 195 layers, 3404320 parameters, 0 gradients, 12.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:43<00:00, 10.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.593      0.592      0.607      0.452       0.59      0.515      0.564      0.372\n",
      "                person        128        254      0.792      0.705      0.783      0.551      0.792      0.634      0.727      0.394\n",
      "               bicycle        128          6      0.437      0.333      0.388      0.215       0.73      0.333      0.482      0.205\n",
      "                   car        128         46      0.518       0.21      0.268      0.152      0.519      0.196      0.229     0.0983\n",
      "            motorcycle        128          5       0.87          1      0.995      0.815          1      0.796      0.995      0.584\n",
      "              airplane        128          6      0.659      0.833      0.931       0.75      0.535      0.667      0.753       0.56\n",
      "                   bus        128          7      0.644      0.714      0.721      0.618      0.653      0.714      0.721      0.591\n",
      "                 train        128          3      0.424      0.667       0.83      0.604      0.438      0.667       0.83      0.604\n",
      "                 truck        128         12      0.751      0.252      0.476      0.254      0.823       0.25      0.449      0.253\n",
      "                  boat        128          6      0.595      0.491      0.497      0.317      0.468      0.333      0.398      0.148\n",
      "         traffic light        128         14      0.643      0.214      0.215      0.145      0.447      0.143      0.159      0.141\n",
      "             stop sign        128          2          1      0.921      0.995      0.747          1      0.896      0.995      0.722\n",
      "                 bench        128          9      0.592      0.324      0.577      0.238      0.425      0.222      0.365      0.106\n",
      "                  bird        128         16      0.937      0.936      0.966      0.698       0.87      0.835      0.895      0.512\n",
      "                   cat        128          4      0.722          1      0.995      0.778      0.741          1      0.995      0.838\n",
      "                   dog        128          9      0.634      0.771      0.844      0.663      0.625      0.744      0.785      0.545\n",
      "                 horse        128          2      0.509          1      0.995      0.597      0.275        0.5      0.497      0.199\n",
      "              elephant        128         17      0.943      0.824      0.896       0.73      0.948      0.824      0.881      0.589\n",
      "                  bear        128          1      0.615          1      0.995      0.995      0.638          1      0.995      0.995\n",
      "                 zebra        128          4      0.827          1      0.995      0.971      0.838          1      0.995      0.853\n",
      "               giraffe        128          9      0.753          1      0.995      0.703      0.742      0.889      0.888      0.475\n",
      "              backpack        128          6      0.723      0.445      0.569       0.29      0.704      0.409      0.417      0.263\n",
      "              umbrella        128         18      0.739      0.722      0.781       0.51      0.577      0.444      0.479      0.231\n",
      "               handbag        128         19      0.716      0.105      0.216      0.162      0.871      0.105      0.223      0.104\n",
      "                   tie        128          7        0.8      0.571      0.601      0.426      0.795      0.557      0.601      0.348\n",
      "              suitcase        128          4      0.652          1      0.912      0.729      0.644       0.75      0.912        0.6\n",
      "               frisbee        128          5      0.553      0.748      0.663      0.599      0.523      0.664      0.687      0.464\n",
      "                  skis        128          1      0.601          1      0.995      0.796      0.686          1      0.995      0.199\n",
      "             snowboard        128          7      0.449      0.714      0.734      0.545      0.378      0.571       0.41      0.185\n",
      "           sports ball        128          6      0.719      0.438      0.438      0.231      0.378      0.211       0.27      0.225\n",
      "                  kite        128         10      0.589        0.3      0.412      0.202      0.431        0.2      0.235      0.145\n",
      "          baseball bat        128          4       0.41       0.25      0.246     0.0604      0.474       0.25      0.225       0.12\n",
      "        baseball glove        128          7      0.661      0.429       0.43      0.269      0.685      0.429       0.43      0.328\n",
      "            skateboard        128          5      0.484        0.2      0.286       0.17      0.551        0.2      0.337      0.181\n",
      "         tennis racket        128          7      0.458      0.429      0.411      0.276      0.484      0.429      0.432      0.268\n",
      "                bottle        128         18      0.435      0.333      0.365      0.191      0.427      0.278      0.362      0.185\n",
      "            wine glass        128         16       0.58      0.625      0.618      0.341      0.601        0.5       0.42      0.262\n",
      "                   cup        128         36      0.603      0.306      0.385      0.288      0.651      0.306      0.359      0.255\n",
      "                  fork        128          6      0.374      0.167      0.221      0.193      0.398      0.167      0.216      0.106\n",
      "                 knife        128         16      0.638      0.438      0.558      0.409      0.662      0.438      0.489      0.348\n",
      "                 spoon        128         22      0.695      0.273      0.434      0.277      0.742      0.273      0.426      0.229\n",
      "                  bowl        128         28      0.657      0.714      0.697      0.569      0.749       0.64       0.65      0.353\n",
      "                banana        128          1      0.139          1      0.142      0.114          0          0      0.142     0.0995\n",
      "              sandwich        128          2      0.333          1      0.414      0.398       0.24        0.5      0.414      0.337\n",
      "                orange        128          4          1          0      0.628      0.435          1          0      0.628      0.414\n",
      "              broccoli        128         11      0.382      0.182      0.289       0.24      0.415      0.182      0.336      0.251\n",
      "                carrot        128         24      0.508        0.5      0.567      0.391      0.584      0.458      0.566      0.333\n",
      "               hot dog        128          2      0.368          1      0.828      0.828       0.38          1      0.828      0.712\n",
      "                 pizza        128          5       0.52          1      0.938       0.73      0.535          1      0.898      0.746\n",
      "                 donut        128         14      0.634      0.989      0.942       0.87       0.63      0.973      0.942      0.766\n",
      "                  cake        128          4      0.596          1      0.995      0.914      0.614          1      0.995      0.834\n",
      "                 chair        128         35      0.379      0.489      0.448      0.227      0.459      0.514      0.437       0.19\n",
      "                 couch        128          6       0.54      0.667      0.705      0.546      0.423        0.5      0.561       0.31\n",
      "          potted plant        128         14       0.72      0.552      0.603      0.384      0.795      0.557      0.684      0.311\n",
      "                   bed        128          3      0.998          1      0.995      0.518          1      0.907      0.995       0.38\n",
      "          dining table        128         13      0.533      0.538      0.465      0.351     0.0917     0.0769      0.152     0.0771\n",
      "                toilet        128          2      0.444        0.5      0.518      0.514      0.483        0.5      0.518      0.512\n",
      "                    tv        128          2       0.52          1      0.995      0.846      0.595          1      0.995      0.896\n",
      "                laptop        128          3      0.593      0.333      0.505      0.472      0.638      0.333      0.519      0.294\n",
      "                 mouse        128          2          0          0      0.092      0.021          0          0     0.0235     0.0118\n",
      "                remote        128          8      0.803      0.509      0.626      0.497      0.814        0.5      0.649      0.472\n",
      "            cell phone        128          8      0.394       0.25      0.184     0.0939      0.449       0.25      0.178     0.0982\n",
      "             microwave        128          3      0.573          1      0.913      0.806      0.647          1      0.913      0.757\n",
      "                  oven        128          5      0.334        0.4      0.336      0.267      0.735        0.6      0.604      0.419\n",
      "                  sink        128          6      0.279      0.167      0.276      0.214      0.315      0.167      0.288      0.207\n",
      "          refrigerator        128          5      0.739        0.8      0.765      0.537      0.787      0.748      0.765      0.513\n",
      "                  book        128         29      0.455      0.231      0.345      0.174      0.341      0.103      0.258      0.101\n",
      "                 clock        128          9      0.693      0.778      0.814       0.68      0.782      0.778      0.814      0.693\n",
      "                  vase        128          2      0.251          1      0.497       0.46      0.291          1      0.497       0.41\n",
      "              scissors        128          1          1          0          0          0          1          0          0          0\n",
      "            teddy bear        128         21       0.66       0.37      0.494      0.323      0.689      0.286      0.423      0.227\n",
      "            toothbrush        128          5      0.324        0.4      0.439      0.197      0.214        0.2      0.439      0.232\n",
      "Speed: 1.6ms preprocess, 292.8ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/bus.jpg: 640x480 4 persons, 1 bus, 1 skateboard, 117.8ms\n",
      "Speed: 2.8ms preprocess, 117.8ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: ultralytics.engine.results.Masks object\n",
       " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       " obb: None\n",
       " orig_img: array([[[122, 148, 172],\n",
       "         [120, 146, 170],\n",
       "         [125, 153, 177],\n",
       "         ...,\n",
       "         [157, 170, 184],\n",
       "         [158, 171, 185],\n",
       "         [158, 171, 185]],\n",
       " \n",
       "        [[127, 153, 177],\n",
       "         [124, 150, 174],\n",
       "         [127, 155, 179],\n",
       "         ...,\n",
       "         [158, 171, 185],\n",
       "         [159, 172, 186],\n",
       "         [159, 172, 186]],\n",
       " \n",
       "        [[128, 154, 178],\n",
       "         [126, 152, 176],\n",
       "         [126, 154, 178],\n",
       "         ...,\n",
       "         [158, 171, 185],\n",
       "         [158, 171, 185],\n",
       "         [158, 171, 185]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[185, 185, 191],\n",
       "         [182, 182, 188],\n",
       "         [179, 179, 185],\n",
       "         ...,\n",
       "         [114, 107, 112],\n",
       "         [115, 105, 111],\n",
       "         [116, 106, 112]],\n",
       " \n",
       "        [[157, 157, 163],\n",
       "         [180, 180, 186],\n",
       "         [185, 186, 190],\n",
       "         ...,\n",
       "         [107,  97, 103],\n",
       "         [102,  92,  98],\n",
       "         [108,  98, 104]],\n",
       " \n",
       "        [[112, 112, 118],\n",
       "         [160, 160, 166],\n",
       "         [169, 170, 174],\n",
       "         ...,\n",
       "         [ 99,  89,  95],\n",
       "         [ 96,  86,  92],\n",
       "         [102,  92,  98]]], dtype=uint8)\n",
       " orig_shape: (1080, 810)\n",
       " path: '/Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/bus.jpg'\n",
       " probs: None\n",
       " save_dir: 'runs/segment/train2'\n",
       " speed: {'preprocess': 2.7997493743896484, 'inference': 117.83671379089355, 'postprocess': 5.239963531494141}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load YOLOv8n-seg, train it on COCO128-seg for 3 epochs and predict an image with it\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n-seg.pt')  # load a pretrained YOLOv8n segmentation model\n",
    "model.train(data='coco128-seg.yaml', epochs=3)  # train the model\n",
    "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ax3p94VNK9zR"
   },
   "source": [
    "## 3. Classification\n",
    "\n",
    "YOLOv8 _classification_ models use the `-cls` suffix, i.e. `yolov8n-cls.pt` and are pretrained on ImageNet. See [Classification Docs](https://docs.ultralytics.com/tasks/classify/) for full details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5q9Zu6zlL5rS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n-cls.pt to 'yolov8n-cls.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.30M/5.30M [00:01<00:00, 4.42MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.42 üöÄ Python-3.11.5 torch-2.2.2 CPU (Apple M2)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=mnist160, epochs=3, time=None, patience=100, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train\n",
      "\n",
      "Dataset not found ‚ö†Ô∏è, missing path /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/mnist160, attempting download...\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v1.0/mnist160.zip to '/Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/mnist160.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70.0k/70.0k [00:00<00:00, 7.10MB/s]\n",
      "Unzipping /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/mnist160.zip to /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/mnist160...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 184/184 [00:00<00:00, 6434.43file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset download success ‚úÖ (0.9s), saved to \u001b[1m/Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/mnist160\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/mnist160/train... found 80 images in 10 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m None...\n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/mnist160/test... found 80 images in 10 classes ‚úÖ \n",
      "Overriding model.yaml nc=1000 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    343050  ultralytics.nn.modules.head.Classify         [256, 10]                     \n",
      "YOLOv8n-cls summary: 99 layers, 1451098 parameters, 1451098 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/mnist160/train... 80 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:00<00:00, 11044.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/mnist160/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/mnist160/test... 80 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:00<00:00, 11198.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/mnist160/test.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/classify/train\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3         0G      2.308         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:04<00:00,  1.09it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0875      0.538\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        2/3         0G      2.337         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:04<00:00,  1.06it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0625      0.613\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        3/3         0G       2.28         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:04<00:00,  1.12it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.112      0.613\n",
      "\n",
      "3 epochs completed in 0.006 hours.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer stripped from runs/classify/train/weights/last.pt, 3.0MB\n",
      "Optimizer stripped from runs/classify/train/weights/best.pt, 3.0MB\n",
      "\n",
      "Validating runs/classify/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.1.42 üöÄ Python-3.11.5 torch-2.2.2 CPU (Apple M2)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 1447690 parameters, 0 gradients, 3.3 GFLOPs\n",
      "WARNING ‚ö†Ô∏è Dataset 'split=val' not found, using 'split=test' instead.\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/mnist160/train... found 80 images in 10 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m None...\n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/mnist160/test... found 80 images in 10 classes ‚úÖ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.112      0.587\n",
      "Speed: 0.0ms preprocess, 23.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/train\u001b[0m\n",
      "Results saved to \u001b[1mruns/classify/train\u001b[0m\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/bus.jpg: 224x224 9 0.21, 6 0.12, 0 0.12, 8 0.11, 1 0.10, 13.6ms\n",
      "Speed: 10.1ms preprocess, 13.6ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: None\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9'}\n",
       " obb: None\n",
       " orig_img: array([[[122, 148, 172],\n",
       "         [120, 146, 170],\n",
       "         [125, 153, 177],\n",
       "         ...,\n",
       "         [157, 170, 184],\n",
       "         [158, 171, 185],\n",
       "         [158, 171, 185]],\n",
       " \n",
       "        [[127, 153, 177],\n",
       "         [124, 150, 174],\n",
       "         [127, 155, 179],\n",
       "         ...,\n",
       "         [158, 171, 185],\n",
       "         [159, 172, 186],\n",
       "         [159, 172, 186]],\n",
       " \n",
       "        [[128, 154, 178],\n",
       "         [126, 152, 176],\n",
       "         [126, 154, 178],\n",
       "         ...,\n",
       "         [158, 171, 185],\n",
       "         [158, 171, 185],\n",
       "         [158, 171, 185]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[185, 185, 191],\n",
       "         [182, 182, 188],\n",
       "         [179, 179, 185],\n",
       "         ...,\n",
       "         [114, 107, 112],\n",
       "         [115, 105, 111],\n",
       "         [116, 106, 112]],\n",
       " \n",
       "        [[157, 157, 163],\n",
       "         [180, 180, 186],\n",
       "         [185, 186, 190],\n",
       "         ...,\n",
       "         [107,  97, 103],\n",
       "         [102,  92,  98],\n",
       "         [108,  98, 104]],\n",
       " \n",
       "        [[112, 112, 118],\n",
       "         [160, 160, 166],\n",
       "         [169, 170, 174],\n",
       "         ...,\n",
       "         [ 99,  89,  95],\n",
       "         [ 96,  86,  92],\n",
       "         [102,  92,  98]]], dtype=uint8)\n",
       " orig_shape: (1080, 810)\n",
       " path: '/Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/bus.jpg'\n",
       " probs: ultralytics.engine.results.Probs object\n",
       " save_dir: 'runs/classify/train2'\n",
       " speed: {'preprocess': 10.135889053344727, 'inference': 13.637065887451172, 'postprocess': 0.052928924560546875}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load YOLOv8n-cls, train it on mnist160 for 3 epochs and predict an image with it\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n-cls.pt')  # load a pretrained YOLOv8n classification model\n",
    "model.train(data='mnist160', epochs=3)  # train the model\n",
    "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpIaFLiO11TG"
   },
   "source": [
    "## 4. Pose\n",
    "\n",
    "YOLOv8 _pose_ models use the `-pose` suffix, i.e. `yolov8n-pose.pt` and are pretrained on COCO Keypoints. See [Pose Docs](https://docs.ultralytics.com/tasks/pose/) for full details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "si4aKFNg19vX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n-pose.pt to 'yolov8n-pose.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.51M/6.51M [00:00<00:00, 10.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.42 üöÄ Python-3.11.5 torch-2.2.2 CPU (Apple M2)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=pose, mode=train, model=yolov8n-pose.pt, data=coco8-pose.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/pose/train\n",
      "\n",
      "Dataset 'coco8-pose.yaml' images not found ‚ö†Ô∏è, missing path '/Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/coco8-pose/images/val'\n",
      "Downloading https://ultralytics.com/assets/coco8-pose.zip to '/Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/coco8-pose.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 334k/334k [00:00<00:00, 10.6MB/s]\n",
      "Unzipping /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/coco8-pose.zip to /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/coco8-pose...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:00<00:00, 3259.73file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset download success ‚úÖ (1.3s), saved to \u001b[1m/Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets\u001b[0m\n",
      "\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   1035934  ultralytics.nn.modules.head.Pose             [1, [17, 3], [64, 128, 256]]  \n",
      "YOLOv8n-pose summary: 250 layers, 3295470 parameters, 3295454 gradients, 9.3 GFLOPs\n",
      "\n",
      "Transferred 397/397 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/pose/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/coco8-pose/labels/train... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 1691.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/coco8-pose/labels/train.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/coco8-pose/labels/val... 4 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 2562.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/datasets/coco8-pose/labels/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/pose/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 63 weight(decay=0.0), 73 weight(decay=0.0005), 72 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/pose/train\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3         0G     0.9887      2.052     0.2933      0.749        1.2          9        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  2.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.927      0.914      0.907      0.668      0.846        0.5      0.535      0.352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3         0G      1.026      3.722     0.4694     0.8057       1.23         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.907      0.929      0.907      0.668      0.842        0.5      0.535      0.354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3         0G      1.191      3.659      0.408       1.04      1.232         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.859      0.929      0.907      0.677      0.839        0.5      0.535      0.358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.004 hours.\n",
      "Optimizer stripped from runs/pose/train/weights/last.pt, 6.8MB\n",
      "Optimizer stripped from runs/pose/train/weights/best.pt, 6.8MB\n",
      "\n",
      "Validating runs/pose/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.1.42 üöÄ Python-3.11.5 torch-2.2.2 CPU (Apple M2)\n",
      "YOLOv8n-pose summary (fused): 187 layers, 3289964 parameters, 0 gradients, 9.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.859      0.929      0.907      0.677      0.839        0.5      0.535      0.358\n",
      "Speed: 2.4ms preprocess, 163.2ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/pose/train\u001b[0m\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 /Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/bus.jpg: 640x480 4 persons, 87.8ms\n",
      "Speed: 2.5ms preprocess, 87.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[122, 148, 172],\n",
       "         [120, 146, 170],\n",
       "         [125, 153, 177],\n",
       "         ...,\n",
       "         [157, 170, 184],\n",
       "         [158, 171, 185],\n",
       "         [158, 171, 185]],\n",
       " \n",
       "        [[127, 153, 177],\n",
       "         [124, 150, 174],\n",
       "         [127, 155, 179],\n",
       "         ...,\n",
       "         [158, 171, 185],\n",
       "         [159, 172, 186],\n",
       "         [159, 172, 186]],\n",
       " \n",
       "        [[128, 154, 178],\n",
       "         [126, 152, 176],\n",
       "         [126, 154, 178],\n",
       "         ...,\n",
       "         [158, 171, 185],\n",
       "         [158, 171, 185],\n",
       "         [158, 171, 185]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[185, 185, 191],\n",
       "         [182, 182, 188],\n",
       "         [179, 179, 185],\n",
       "         ...,\n",
       "         [114, 107, 112],\n",
       "         [115, 105, 111],\n",
       "         [116, 106, 112]],\n",
       " \n",
       "        [[157, 157, 163],\n",
       "         [180, 180, 186],\n",
       "         [185, 186, 190],\n",
       "         ...,\n",
       "         [107,  97, 103],\n",
       "         [102,  92,  98],\n",
       "         [108,  98, 104]],\n",
       " \n",
       "        [[112, 112, 118],\n",
       "         [160, 160, 166],\n",
       "         [169, 170, 174],\n",
       "         ...,\n",
       "         [ 99,  89,  95],\n",
       "         [ 96,  86,  92],\n",
       "         [102,  92,  98]]], dtype=uint8)\n",
       " orig_shape: (1080, 810)\n",
       " path: '/Users/jonathanricardo/Library/CloudStorage/OneDrive-HvA/Semester 4 - AI/Logboek AAI/minor-logboek-aai-2023-jonathan/deeplearning/computer_vision/yolo/bus.jpg'\n",
       " probs: None\n",
       " save_dir: 'runs/pose/train2'\n",
       " speed: {'preprocess': 2.516031265258789, 'inference': 87.80193328857422, 'postprocess': 0.7472038269042969}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load YOLOv8n-pose, train it on COCO8-pose for 3 epochs and predict an image with it\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n-pose.pt')  # load a pretrained YOLOv8n pose model\n",
    "model.train(data='coco8-pose.yaml', epochs=3)  # train the model\n",
    "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb",
     "timestamp": 1712055108696
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
