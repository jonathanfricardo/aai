{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings, Conv1D en Recurrente netwerken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Jonathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 1: Verover de data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gebruiken de IMDB dataset met filmrecensies. Deze hebben we tijdens de bootcamp ook al eens bekeken. ter herinnering: de labels zijn binair en geven aan of een film wel of geen aanrader is volgens de reviews.\n",
    "\n",
    "We maken het ons zelf iets moeilijker door van elke review alleen de eerste 20 woorden te gebruiken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import preprocessing\n",
    "\n",
    "max_features = 10000\n",
    "maxlen = 20 # gebruik alleen de eerste 20 woorden van iedere review (voor efficiency)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = max_features)\n",
    "\n",
    "# gebruik alleen de eerste 20 woorden\n",
    "# vul sequences korter dan 20 woorden aan met nullen\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen = maxlen)\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen = maxlen)\n",
    "\n",
    "x_val_set = x_train[:10000]\n",
    "x_train_set = x_train[10000:]\n",
    "\n",
    "y_val_set = y_train[:10000]\n",
    "y_train_set = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 20) (15000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_set.shape, y_train_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 2: Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We trainen een embedding layer in combinatie met een Dense netwerk. In onderstaande code zijn de lagen voor de embedding al ingevuld. Maak het netwerk af met een of meer dense lagen, compileer en train dit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Jonathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Jonathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 20, 16)            160000    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 320)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 1284      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161289 (630.04 KB)\n",
      "Trainable params: 161289 (630.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 16, input_length = maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\Jonathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Jonathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "469/469 [==============================] - 2s 2ms/step - loss: 0.6878 - acc: 0.5361 - val_loss: 0.6718 - val_acc: 0.6580\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.6325 - acc: 0.6389 - val_loss: 0.5832 - val_acc: 0.7331\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.5577 - acc: 0.7306 - val_loss: 0.5234 - val_acc: 0.7519\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4944 - acc: 0.7747 - val_loss: 0.5001 - val_acc: 0.7545\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4580 - acc: 0.8008 - val_loss: 0.5012 - val_acc: 0.7523\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4173 - acc: 0.8253 - val_loss: 0.5065 - val_acc: 0.7489\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3862 - acc: 0.8465 - val_loss: 0.5272 - val_acc: 0.7436\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3529 - acc: 0.8629 - val_loss: 0.5547 - val_acc: 0.7393\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3274 - acc: 0.8746 - val_loss: 0.5750 - val_acc: 0.7318\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2994 - acc: 0.8891 - val_loss: 0.6063 - val_acc: 0.7258\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history = model.fit(x_train_set, y_train_set, epochs = 10, batch_size = 32, validation_data = (x_val_set, y_val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 704us/step - loss: 0.6097 - acc: 0.7271\n",
      "[0.6097189784049988, 0.7271199822425842]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 3: 1D Convolutie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimenteer met een netwerk met een Embedding en een of meer `Conv1D` lagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Jonathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 20, 16)            160000    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 14, 32)            3616      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 4, 32)             0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 2, 32)             3104      \n",
      "                                                                 \n",
      " global_max_pooling1d (Glob  (None, 32)                0         \n",
      " alMaxPooling1D)                                                 \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 264       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166993 (652.32 KB)\n",
      "Trainable params: 166993 (652.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 16, input_length = maxlen))\n",
    "model.add(Conv1D(32, 7, activation = 'relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Conv1D(32, 3, activation = 'relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.6587 - acc: 0.5920 - val_loss: 0.5858 - val_acc: 0.6844\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.5257 - acc: 0.7369 - val_loss: 0.5388 - val_acc: 0.7220\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.4545 - acc: 0.7884 - val_loss: 0.5485 - val_acc: 0.7230\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.4043 - acc: 0.8205 - val_loss: 0.5567 - val_acc: 0.7217\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.3508 - acc: 0.8507 - val_loss: 0.5981 - val_acc: 0.7172\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2929 - acc: 0.8813 - val_loss: 0.6408 - val_acc: 0.7144\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2322 - acc: 0.9109 - val_loss: 0.7849 - val_acc: 0.6909\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1761 - acc: 0.9361 - val_loss: 0.8092 - val_acc: 0.6927\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1260 - acc: 0.9573 - val_loss: 0.9461 - val_acc: 0.6803\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0854 - acc: 0.9707 - val_loss: 1.0984 - val_acc: 0.6852\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.0768 - acc: 0.6842\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history = model.fit(x_train_set, y_train_set, epochs = 10, batch_size = 32, validation_data = (x_val_set, y_val_set))\n",
    "\n",
    "# Evaluate the model\n",
    "results = model.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, 20, 16)            160000    \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 14, 32)            3616      \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 14, 32)            0         \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPoolin  (None, 4, 32)             0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_16 (Conv1D)          (None, 2, 32)             3104      \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 2, 32)             0         \n",
      "                                                                 \n",
      " global_max_pooling1d_7 (Gl  (None, 32)                0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 8)                 264       \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166993 (652.32 KB)\n",
      "Trainable params: 166993 (652.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 16, input_length = maxlen))\n",
    "model.add(Conv1D(32, 7, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Conv1D(32, 3, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.6816 - acc: 0.5476 - val_loss: 0.6468 - val_acc: 0.6612\n",
      "Epoch 2/8\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.6064 - acc: 0.6761 - val_loss: 0.5881 - val_acc: 0.7062\n",
      "Epoch 3/8\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.5573 - acc: 0.7308 - val_loss: 0.5638 - val_acc: 0.7067\n",
      "Epoch 4/8\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.5325 - acc: 0.7509 - val_loss: 0.5549 - val_acc: 0.7148\n",
      "Epoch 5/8\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.5109 - acc: 0.7681 - val_loss: 0.5455 - val_acc: 0.7271\n",
      "Epoch 6/8\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.4892 - acc: 0.7823 - val_loss: 0.5411 - val_acc: 0.7188\n",
      "Epoch 7/8\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.4790 - acc: 0.7914 - val_loss: 0.5425 - val_acc: 0.7213\n",
      "Epoch 8/8\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.4574 - acc: 0.8042 - val_loss: 0.5474 - val_acc: 0.7156\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.5429 - acc: 0.7186\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history = model.fit(x_train_set, y_train_set, epochs = 8, batch_size = 16, validation_data = (x_val_set, y_val_set))\n",
    "\n",
    "# Evaluate the model\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## BONUS: pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
