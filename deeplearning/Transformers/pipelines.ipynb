{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Pipelines for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blPbrTHFIqee"
   },
   "source": [
    "\n",
    "In this notebook, we look at a few tasks for which we can run inference on pretrained models using predefined pipelines. The complete list of tasks for which a pipeline is available can be found here: https://huggingface.co/docs/transformers/main_classes/pipelines.\n",
    "\n",
    "If you are using Google Colab, make sure that you are using a GPU (Runtime > Change runtime type > Hardware accelerator > GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "W7jI09pbQUrs",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/jonathanricardo/anaconda3/lib/python3.11/site-packages (4.36.2)\n",
      "Requirement already satisfied: filelock in /Users/jonathanricardo/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/jonathanricardo/anaconda3/lib/python3.11/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/jonathanricardo/anaconda3/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jonathanricardo/anaconda3/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/jonathanricardo/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/jonathanricardo/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/jonathanricardo/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/jonathanricardo/anaconda3/lib/python3.11/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/jonathanricardo/anaconda3/lib/python3.11/site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/jonathanricardo/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/jonathanricardo/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/jonathanricardo/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jonathanricardo/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jonathanricardo/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jonathanricardo/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jonathanricardo/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2023.11.17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanricardo/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/jonathanricardo/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# First, we need to install the transformers library and import the pipeline.\n",
    "!pip install transformers\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTB_ILtlJZ2Q"
   },
   "source": [
    "### 1 Sentiment analysis pipeline\n",
    "\n",
    "To start with, we look at a sentiment analysis example.\n",
    "\n",
    "Run the code below. Try it also on some sentence where the sentiment is not as obvious. Are you still getting good results?:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Tg4VFo_bREus"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f47d8ee4fe54f7aa501b426de67fb63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af4d60c952b34743b30a6a557d56d144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73113d2b299f4c8ea7be1833d31d4a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f3e097280cf427f82fef21b10ec00c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GDDNBteRGoKI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  Transformers are cool models with great performance on most NLP tasks.\n",
      "label: POSITIVE, with score: 0.9997\n",
      "\n",
      "Text:  I don't want to learn about all these different models, it's boring.\n",
      "label: NEGATIVE, with score: 0.9995\n",
      "\n",
      "Text:  Some times i enjoy going out but i like to stay at home too.\n",
      "label: POSITIVE, with score: 0.9983\n",
      "\n",
      "Text:  I love my dog, but I hate him too.\n",
      "label: NEGATIVE, with score: 0.9669\n",
      "\n",
      "Text:  I hate my dog, but I love him too\n",
      "label: POSITIVE, with score: 0.9988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Transformers are cool models with great performance on most NLP tasks.\",\n",
    "    \"I don't want to learn about all these different models, it's boring.\",\n",
    "    \"Some times i enjoy going out but i like to stay at home too.\",\n",
    "    \"I love my dog, but I hate him too.\",\n",
    "    \"I hate my dog, but I love him too\"\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "  print(\"Text: \", text)\n",
    "  result = classifier(text)[0]\n",
    "  print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0jiWx3tJ68L"
   },
   "source": [
    "### 2 Summarization pipeline\n",
    "\n",
    "Next, we try the text summarization pipeline.\n",
    "\n",
    "Run the code below. Try it also with your own text and/or different summary lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SKNkUwopQUx6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb5614ba0394c6ea9f8ba29acd27c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae6ff15ef1642c5937993642058ba3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3997e70dabf34caeb73f6d2acf17ead0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2afa77d648e841ca81d79a840778ac1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66d828547954fd79432dbd11ba23bb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "IqaoHOztGig1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': ' A transformer is a deep learning model that adopts the mechanism of self-attention, differentially weighting the significance of each part of the input data . It is used primarily in the fields of natural language processing (NLP) and computer vision .'}]\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "A transformer is a deep learning model that adopts the mechanism of self-attention, differentially weighting the significance of each part of the input data.\n",
    "It is used primarily in the fields of natural language processing (NLP) and computer vision (CV).\n",
    "\n",
    "Like recurrent neural networks (RNNs), transformers are designed to process sequential input data, such as natural language,\n",
    "with applications towards tasks such as translation and text summarization. However, unlike RNNs, transformers process the entire input all at once.\n",
    "The attention mechanism provides context for any position in the input sequence. For example, if the input data is a natural language sentence,\n",
    "the transformer does not have to process one word at a time. This allows for more parallelization than RNNs and therefore reduces training times.\n",
    "\n",
    "Transformers were introduced in 2017 by a team at Google Brain and are increasingly the model of choice for NLP problems,\n",
    " replacing RNN models such as long short-term memory (LSTM). The additional training parallelization allows training on larger datasets.\n",
    " This led to the development of pretrained systems such as BERT (Bidirectional Encoder Representations from Transformers)\n",
    " and GPT (Generative Pre-trained Transformer), which were trained with large language datasets, such as the Wikipedia Corpus and Common Crawl,\n",
    " and can be fine-tuned for specific tasks.\n",
    "\"\"\"\n",
    "print(summarizer(text, max_length=130, min_length=30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mytvu55pImKJ"
   },
   "source": [
    "### 3 Question answering pipeline\n",
    "\n",
    "The question answering pipeline does not generate answers on its own, but extracts them from the supplied text (in the example below: the Wikipedia article on the Transformer).\n",
    "\n",
    "Run the code and try it with your own examples if you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "p8e_-us9YJcr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05507c41abe24286a2b1c5b62d132e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ebea34039de4c6a910abc830669cace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2903f66f3ccc411baadc2891ba36a615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9361d1c8ae4540699ebfa6ad86f0c4e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d15f33a43c4f9ab002d752b9469e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question_answerer = pipeline(\"question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B8Xf9QeoFz3c",
    "outputId": "a19c156a-ce61-4f8f-cb62-e94702a313f0",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is a transformer?\n",
      "Answer: 'a deep learning model', score: 0.5247, start: 18, end: 39\n",
      "\n",
      "Question:  In what fields are transformers primarily used?\n",
      "Answer: 'natural language processing (NLP) and computer vision (CV)', score: 0.5768, start: 197, end: 255\n",
      "\n",
      "Question:  When were transformers introduced?\n",
      "Answer: '2017', score: 0.9723, start: 855, end: 859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context = r\"\"\"\n",
    "A transformer is a deep learning model that adopts the mechanism of self-attention, differentially weighting the significance of each part of the input data.\n",
    "It is used primarily in the fields of natural language processing (NLP) and computer vision (CV).\n",
    "\n",
    "Like recurrent neural networks (RNNs), transformers are designed to process sequential input data, such as natural language,\n",
    "with applications towards tasks such as translation and text summarization. However, unlike RNNs, transformers process the entire input all at once.\n",
    "The attention mechanism provides context for any position in the input sequence. For example, if the input data is a natural language sentence,\n",
    "the transformer does not have to process one word at a time. This allows for more parallelization than RNNs and therefore reduces training times.\n",
    "\n",
    "Transformers were introduced in 2017 by a team at Google Brain and are increasingly the model of choice for NLP problems,\n",
    " replacing RNN models such as long short-term memory (LSTM). The additional training parallelization allows training on larger datasets.\n",
    " This led to the development of pretrained systems such as BERT (Bidirectional Encoder Representations from Transformers)\n",
    " and GPT (Generative Pre-trained Transformer), which were trained with large language datasets, such as the Wikipedia Corpus and Common Crawl,\n",
    " and can be fine-tuned for specific tasks.\n",
    "\"\"\"\n",
    "\n",
    "questions = [\n",
    "    \"What is a transformer?\",\n",
    "    \"In what fields are transformers primarily used?\",\n",
    "    \"When were transformers introduced?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "  print(\"Question: \", question)\n",
    "  result = question_answerer(question=question, context=context)\n",
    "  print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKRI2lkRKGUF"
   },
   "source": [
    "### 4 Text generation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "UFqcV_0kYkBP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb80c452a2f45e9a21e0eae6032e588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanricardo/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1474f81e683142de9333ebd84a3602e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e96b63fef1ac460bb86594e6944df5df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2052b51d71b147fcbd1bc2dad10057c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "548d340234914b1e91b9f6ab43cf10a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99aac5d8aa664e098f1b495bdc514532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aef202d7d5c47889def1e7ce86c77fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_generator = pipeline(\"text-generation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FL0vSek23-K"
   },
   "source": [
    "Try running the following cell several times and see how the output changes. Are you getting reasonable results? Try it with your own prompts! You can also change the maximum length of the generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dP9mTtq8G4kz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'A transformer is a deep learning model that describes the computation of discrete neural networks with recurrent weights (Figure 1B). In an example, the training block for the first neuron is computed by averaging the inputs onto a recurrent neural network to train that network. When a neural network has tens of thousands to millions of neurons in it, it can compute the tens of thousands of neural networks needed to solve for weights (Supplementary Fig. 1). We call for some way of solving for it: an NNN'}]\n"
     ]
    }
   ],
   "source": [
    "print(text_generator(\"A transformer is a deep learning model that\", max_length=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YvHM3gTr5QB"
   },
   "source": [
    "### 5 Running a pipeline with your chosen pretrained model\n",
    "\n",
    "As you may have noticed, the pipeline for each task is associated with a default model, which is automatically downloaded if no model is specified. However, it is also possible to specify the model that you want to use explicitly. Run inference on one of the above (or other) tasks using a different model.\n",
    "\n",
    "The list of available pretrained models can be found here: https://huggingface.co/models. Tip: filter the models by language and task first (sentiment analysis falls under text classification).\n",
    "\n",
    "If you click on your chosen model, the model card should show instructions on how to use it, e.g. https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english.\n",
    "\n",
    "Try a different model on one of the tasks. How do the results compare to the default model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "UGTa2dQ7yhjP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'SQuAD dataset', score: 0.5152, start: 151, end: 164\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "question_answerer = pipeline(\"question-answering\", model='distilbert-base-cased-distilled-squad')\n",
    "\n",
    "context = r\"\"\"\n",
    "Extractive Question Answering is the task of extracting an answer from a text given a question. An example     of a\n",
    "question answering dataset is the SQuAD dataset, which is entirely based on that task. If you would like to fine-tune\n",
    "a model on a SQuAD task, you may leverage the examples/pytorch/question-answering/run_squad.py script.\n",
    "\"\"\"\n",
    "\n",
    "result = question_answerer(question=\"What is a good example of a question answering dataset?\",     context=context)\n",
    "print(\n",
    "f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is a transformer?\n",
      "Answer: 'a deep learning model', score: 0.5247, start: 18, end: 39\n",
      "\n",
      "Question:  In what fields are transformers primarily used?\n",
      "Answer: 'natural language processing (NLP) and computer vision (CV)', score: 0.5768, start: 197, end: 255\n",
      "\n",
      "Question:  When were transformers introduced?\n",
      "Answer: '2017', score: 0.9723, start: 855, end: 859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "question_answerer = pipeline(\"question-answering\", model='distilbert-base-cased-distilled-squad')\n",
    "\n",
    "context = r\"\"\"\n",
    "A transformer is a deep learning model that adopts the mechanism of self-attention, differentially weighting the significance of each part of the input data.\n",
    "It is used primarily in the fields of natural language processing (NLP) and computer vision (CV).\n",
    "\n",
    "Like recurrent neural networks (RNNs), transformers are designed to process sequential input data, such as natural language,\n",
    "with applications towards tasks such as translation and text summarization. However, unlike RNNs, transformers process the entire input all at once.\n",
    "The attention mechanism provides context for any position in the input sequence. For example, if the input data is a natural language sentence,\n",
    "the transformer does not have to process one word at a time. This allows for more parallelization than RNNs and therefore reduces training times.\n",
    "\n",
    "Transformers were introduced in 2017 by a team at Google Brain and are increasingly the model of choice for NLP problems,\n",
    " replacing RNN models such as long short-term memory (LSTM). The additional training parallelization allows training on larger datasets.\n",
    " This led to the development of pretrained systems such as BERT (Bidirectional Encoder Representations from Transformers)\n",
    " and GPT (Generative Pre-trained Transformer), which were trained with large language datasets, such as the Wikipedia Corpus and Common Crawl,\n",
    " and can be fine-tuned for specific tasks.\n",
    "\"\"\"\n",
    "\n",
    "questions = [\n",
    "    \"What is a transformer?\",\n",
    "    \"In what fields are transformers primarily used?\",\n",
    "    \"When were transformers introduced?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "  print(\"Question: \", question)\n",
    "  result = question_answerer(question=question, context=context)\n",
    "  print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
