{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In deze opgave classificeren afbeeldingen van bloemen uit de iris dataset met behulp van een neuraal netwerk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laad de dataset en maak een feature matrix X en een target vector y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = sns.load_dataset('iris')\n",
    "\n",
    "# we gebruiken .values om een Numpy array te krijgen in plaats van een Pandas DataFrame\n",
    "X_iris = iris.drop('species', axis=1).values \n",
    "y_iris = iris['species'].values\n",
    "\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['setosa']\n",
      " ['setosa']\n",
      " ['setosa']\n",
      " ['setosa']\n",
      " ['setosa']\n",
      " ['setosa']\n",
      " ['setosa']\n",
      " ['setosa']\n",
      " ['setosa']\n",
      " ['setosa']]\n"
     ]
    }
   ],
   "source": [
    "y_iris = y_iris.reshape(-1, 1) # maak een array van array's, dit is nodig voor de volgende stap\n",
    "print(y_iris[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Een neuraal netwerk kan niet omgaan met categorische labels zoals de namen van de planten, maar heeft getallen als uitput nodig. We hebben hier drie klassen (setosa, versicolor, virginica) daarom maken we een target vector met per label drie waarden. Een 1 voor de eerste waarde correspondeert met 'setosa', een 1 voor de 2e waade met 'versicolor' en een 1 voor de derde waarde met 'virginica'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doe dit met behulp van het `OneHotEncoder` object uit sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Replaces species with numbers\n",
    "enc = OneHotEncoder()\n",
    "y_iris = enc.fit_transform(y_iris).toarray()\n",
    "print(y_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hebben de data nu in een geschikt formaat. Splits de data in training en test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_iris, y_iris, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maak een eenvoudig neuraal netwerk met 3 lagen, waarin elke neuron in een laag met elk neuron in de vorige laag verbonden is ('Dense'). \n",
    "Voeg voor de eeste laag een parameter `input_shape` toe die aangeeft hoeveel features een element in 'X' heeft.\n",
    "Het aantal neuronen in de laaste laag is gelijk aan het aantal waarden in een label in `y`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#voeg lagen toe met model.add()\n",
    "model.add(Dense(4, input_shape=(4,), activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.add(Dense(3, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compileer en bekijk het netwerk door onderstaande code te runnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 25        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 63 (252.00 Byte)\n",
      "Trainable params: 63 (252.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers.legacy import Adam\n",
    "\n",
    "model.compile(Adam(learning_rate=0.01),'categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu kunnen we ons model trainen met behulp van de `fit` methode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "24/24 [==============================] - 0s 845us/step - loss: 1.0560 - accuracy: 0.4083\n",
      "Epoch 2/40\n",
      "24/24 [==============================] - 0s 641us/step - loss: 0.9543 - accuracy: 0.5167\n",
      "Epoch 3/40\n",
      "24/24 [==============================] - 0s 589us/step - loss: 0.8136 - accuracy: 0.7417\n",
      "Epoch 4/40\n",
      "24/24 [==============================] - 0s 557us/step - loss: 0.6913 - accuracy: 0.7917\n",
      "Epoch 5/40\n",
      "24/24 [==============================] - 0s 559us/step - loss: 0.5915 - accuracy: 0.9083\n",
      "Epoch 6/40\n",
      "24/24 [==============================] - 0s 515us/step - loss: 0.5057 - accuracy: 0.8833\n",
      "Epoch 7/40\n",
      "24/24 [==============================] - 0s 565us/step - loss: 0.4288 - accuracy: 0.9250\n",
      "Epoch 8/40\n",
      "24/24 [==============================] - 0s 566us/step - loss: 0.3639 - accuracy: 0.9250\n",
      "Epoch 9/40\n",
      "24/24 [==============================] - 0s 547us/step - loss: 0.2953 - accuracy: 0.9750\n",
      "Epoch 10/40\n",
      "24/24 [==============================] - 0s 533us/step - loss: 0.2408 - accuracy: 0.9833\n",
      "Epoch 11/40\n",
      "24/24 [==============================] - 0s 568us/step - loss: 0.2231 - accuracy: 0.9667\n",
      "Epoch 12/40\n",
      "24/24 [==============================] - 0s 588us/step - loss: 0.2196 - accuracy: 0.9167\n",
      "Epoch 13/40\n",
      "24/24 [==============================] - 0s 555us/step - loss: 0.1723 - accuracy: 0.9750\n",
      "Epoch 14/40\n",
      "24/24 [==============================] - 0s 536us/step - loss: 0.2607 - accuracy: 0.9000\n",
      "Epoch 15/40\n",
      "24/24 [==============================] - 0s 548us/step - loss: 0.1809 - accuracy: 0.9500\n",
      "Epoch 16/40\n",
      "24/24 [==============================] - 0s 591us/step - loss: 0.1801 - accuracy: 0.9500\n",
      "Epoch 17/40\n",
      "24/24 [==============================] - 0s 546us/step - loss: 0.1628 - accuracy: 0.9583\n",
      "Epoch 18/40\n",
      "24/24 [==============================] - 0s 536us/step - loss: 0.2141 - accuracy: 0.9250\n",
      "Epoch 19/40\n",
      "24/24 [==============================] - 0s 536us/step - loss: 0.1392 - accuracy: 0.9750\n",
      "Epoch 20/40\n",
      "24/24 [==============================] - 0s 556us/step - loss: 0.1446 - accuracy: 0.9333\n",
      "Epoch 21/40\n",
      "24/24 [==============================] - 0s 535us/step - loss: 0.2152 - accuracy: 0.9250\n",
      "Epoch 22/40\n",
      "24/24 [==============================] - 0s 552us/step - loss: 0.1507 - accuracy: 0.9500\n",
      "Epoch 23/40\n",
      "24/24 [==============================] - 0s 529us/step - loss: 0.1466 - accuracy: 0.9417\n",
      "Epoch 24/40\n",
      "24/24 [==============================] - 0s 608us/step - loss: 0.2319 - accuracy: 0.8917\n",
      "Epoch 25/40\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1710 - accuracy: 0.9250\n",
      "Epoch 26/40\n",
      "24/24 [==============================] - 0s 563us/step - loss: 0.1051 - accuracy: 0.9583\n",
      "Epoch 27/40\n",
      "24/24 [==============================] - 0s 527us/step - loss: 0.1168 - accuracy: 0.9500\n",
      "Epoch 28/40\n",
      "24/24 [==============================] - 0s 720us/step - loss: 0.1126 - accuracy: 0.9583\n",
      "Epoch 29/40\n",
      "24/24 [==============================] - 0s 660us/step - loss: 0.1052 - accuracy: 0.9667\n",
      "Epoch 30/40\n",
      "24/24 [==============================] - 0s 531us/step - loss: 0.0906 - accuracy: 0.9667\n",
      "Epoch 31/40\n",
      "24/24 [==============================] - 0s 522us/step - loss: 0.0989 - accuracy: 0.9667\n",
      "Epoch 32/40\n",
      "24/24 [==============================] - 0s 509us/step - loss: 0.0936 - accuracy: 0.9667\n",
      "Epoch 33/40\n",
      "24/24 [==============================] - 0s 487us/step - loss: 0.1076 - accuracy: 0.9500\n",
      "Epoch 34/40\n",
      "24/24 [==============================] - 0s 503us/step - loss: 0.0950 - accuracy: 0.9750\n",
      "Epoch 35/40\n",
      "24/24 [==============================] - 0s 522us/step - loss: 0.1576 - accuracy: 0.9333\n",
      "Epoch 36/40\n",
      "24/24 [==============================] - 0s 533us/step - loss: 0.1357 - accuracy: 0.9500\n",
      "Epoch 37/40\n",
      "24/24 [==============================] - 0s 507us/step - loss: 0.0878 - accuracy: 0.9667\n",
      "Epoch 38/40\n",
      "24/24 [==============================] - 0s 511us/step - loss: 0.0972 - accuracy: 0.9583\n",
      "Epoch 39/40\n",
      "24/24 [==============================] - 0s 533us/step - loss: 0.0773 - accuracy: 0.9750\n",
      "Epoch 40/40\n",
      "24/24 [==============================] - 0s 515us/step - loss: 0.1038 - accuracy: 0.9583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1780b7a10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 40, batch_size = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Met `model_evaluate` kunnen we bepalen hoe goed het model werkt op de test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0810 - accuracy: 0.9667\n",
      "0.9666666388511658\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimenteer met bovenstaand model. Wat gebeurt er als je meer lagen toevoegt of een laag weghaalt of het aantal neuronen in een laag verandert? \n",
    "\n",
    "Met 3 lagen, geeft hij de eerste keer een accuracy van 63% Als ik hem opnieuw run, dan gaat de acuracy omhoog naar 93%. Soms geeft het een accuracy van 100%\n",
    "\n",
    "Ik heb de 2e laag weggehaald, dus het model heeft nu de unput laag en een output laag, dus geen hidden layers.\n",
    "Als ik het model train, dan geeft hij een accuracy rond 80-90%. Als ik de code opnieuw run, krijg ik andere waarden, soms 95% en soms 100% acuracy.\n",
    "\n",
    "Wat mij vooral opvalt is dat het elke keer een ander resultaat geeft, soms geef het een laag resultaat zoals 30%, en soms 100%. Persoonlijk weet ik niet waaraan dit ligt.\n",
    "\n",
    "#### Probeer ook eens andere activatiefuncties dan `relu`, zoals `tanh` of `sigmoid`.\n",
    "\n",
    "Persoonlijk zie ik geen verschil in de resultaten, het geeft weer elke keer een andere accuracy. tussen 60% en 100%\n",
    "\n",
    "#### Welke invloed heeft het aantal epochs?\n",
    "Als ik de epochs van 25 naar 40 zet, gaat de accuracy zeer omhoog. Nu is het altijd tussen 95-100%. Met elke run die ik doe blijft het resultaat ongeveer hetzelfde en blijt stabiel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We kunnen dezelfde aanpak gebruiken voor andere data, bijvoorbeeld voor het herkennen van cijfers. We gebruiken de `MNist` dataset die bestaat uit plaatjes van cijfers. Ieder plaatje bestaat uit 28 x 28 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Een eenvoudig neuraal netwerk heeft een array van inputwaarden nodig i.p.v. een 2D afbeelding.\n",
    "We maken van de inputs (waarden tussen 0 en 255) getallen tussen 0 en 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28)) # lijst van waarden i.p.v. 2D afbeelding\n",
    "train_images = train_images.astype('float32') / 255 # getallen tussen 0 en 1\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor elk label (een cijfer) maken we een array met 10 waarden: 9 nullen en een één, waarbij de positie van de één aangeeft om welk cijfer het gaat (One hot encoding). Dit keer gebruiken we hiervoor de `keras` functie `to_categorical`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maak nu een neuraal netwerk met twee lagen, een eerste laag met 512 neuronen en een output laag met 10 neuronen. Geef bij de eerste laag aan hoeveel inputs er zijn en wat de activatiefunctie is. De output laag heeft een `softmax` activatiefunctie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network with 2 layers\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(28 * 28,))) # 28*28 = 784, because of the size of the images\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compileer het netwerk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407050 (1.55 MB)\n",
      "Trainable params: 407050 (1.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(Adam(learning_rate=0.01),'categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train het netwerk 5 epochs met een batch_size van 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2113 - accuracy: 0.9366\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1099 - accuracy: 0.9670\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0957 - accuracy: 0.9719\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0787 - accuracy: 0.9771\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0726 - accuracy: 0.9797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1780d6290>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evalueer het netwerk op de test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 774us/step - loss: 0.1391 - accuracy: 0.9688\n",
      "0.9688000082969666\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In mijn eerste model heb ik de volgende gegevens: 1e layer met 784 inputs en 512 neurons en activation relu. Ik gebruik 784 input omdat de afbeelding 28 * 28 is, dus 784 pixels in totaal. De output layer is 10 met activation softmax.\n",
    "\n",
    "Wat mij opvalt is dat het een hoge accuracy heeft van ±98%. Wel is het model 'slomer' dan het iris model. Maar dat komt omdat je veel meer verbindingen hebt tussen de neurons, en natuurlijk een hele grote input hebt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimenteer met verschillende netwerken. Varieer het aantal lagen, het aantal neuronen, de activatiefunties en het aantal epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2643 - accuracy: 0.9255\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1383 - accuracy: 0.9589\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1154 - accuracy: 0.9666\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1035 - accuracy: 0.9710\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0964 - accuracy: 0.9736\n",
      "313/313 [==============================] - 0s 983us/step - loss: 0.1588 - accuracy: 0.9621\n",
      "0.9621000289916992\n"
     ]
    }
   ],
   "source": [
    "# Model with extra layer\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(Adam(learning_rate=0.01),'categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Met een extra laag is de accuracy om laag gegaan met ±2% Wat ook opvalt is dat het langer duurt per epoch nu dat er een extra laag in zit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2056 - accuracy: 0.9372\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1145 - accuracy: 0.9656\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0882 - accuracy: 0.9738\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0795 - accuracy: 0.9772\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0678 - accuracy: 0.9808\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0641 - accuracy: 0.9827\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0602 - accuracy: 0.9833\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0529 - accuracy: 0.9858\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0557 - accuracy: 0.9855\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0537 - accuracy: 0.9867\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1693 - accuracy: 0.9730\n",
      "0.9729999899864197\n"
     ]
    }
   ],
   "source": [
    "# Model with more epochs but same amount of layers\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(Adam(learning_rate=0.01),'categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=128)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu is de accuracy iets omhoog gegaan, met ±1%. Dit komt omdat er meer epochs zijn en het model dus langer getraind wordt en de gewichten van het model aangepast worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2590 - accuracy: 0.9246\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1360 - accuracy: 0.9602\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1090 - accuracy: 0.9689\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1080 - accuracy: 0.9700\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0924 - accuracy: 0.9744\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0888 - accuracy: 0.9761\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0823 - accuracy: 0.9774\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0768 - accuracy: 0.9796\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0695 - accuracy: 0.9811\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0688 - accuracy: 0.9819\n",
      "313/313 [==============================] - 0s 928us/step - loss: 0.1553 - accuracy: 0.9724\n",
      "0.9724000096321106\n"
     ]
    }
   ],
   "source": [
    "# Model with more epochs and extra layer\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(Adam(learning_rate=0.01),'categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=128)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het zelfde geld voor dit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.3237 - accuracy: 0.9108\n",
      "Epoch 2/15\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1609 - accuracy: 0.9554\n",
      "Epoch 3/15\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1393 - accuracy: 0.9629\n",
      "Epoch 4/15\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1253 - accuracy: 0.9658\n",
      "Epoch 5/15\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1160 - accuracy: 0.9685\n",
      "Epoch 6/15\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1148 - accuracy: 0.9696\n",
      "Epoch 7/15\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0954 - accuracy: 0.9748\n",
      "Epoch 8/15\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1036 - accuracy: 0.9724\n",
      "Epoch 9/15\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0939 - accuracy: 0.9753\n",
      "Epoch 10/15\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0943 - accuracy: 0.9754\n",
      "Epoch 11/15\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1003 - accuracy: 0.9750\n",
      "Epoch 12/15\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0807 - accuracy: 0.9788\n",
      "Epoch 13/15\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0654 - accuracy: 0.9819\n",
      "Epoch 14/15\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0803 - accuracy: 0.9800\n",
      "Epoch 15/15\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0823 - accuracy: 0.9792\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1648 - accuracy: 0.9652\n",
      "0.9652000069618225\n"
     ]
    }
   ],
   "source": [
    "# Model with even more epochs and more layers\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(Adam(learning_rate=0.01),'categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=15, batch_size=128)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dit model heb ik 2 layers toegevoegd en meer epochs. Dit duurde veel langer, omdat er dus meer lagen zijn en meer epochs. Wat ook opvalt is dat de accuracy met ±1% omlaag gaat.\n",
    "\n",
    "Dit kan komen door verschillende dingen:\n",
    "1. Doordat we zolang trainen op 1 model, betekend dat het model te erg gewend is aan de train data. Als je het model dan gebruikt op de test data, dan performed hij dus slechter omdat het niet lijkt op de train data. Dit noem je Overfitting\n",
    "2. Misschien is ons model te complex voor ons plobleem. Door extra lagen toe te voegen wordt het model zeer complex. Daarom kan het model minder goed scoren op een relatief simpel probleem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
